# 使用mllib完成mnist手写识别任务

小提示，通过restart命令重启已经退出了的容器
```
sudo docker restart <contain id>
```

从http://yann.lecun.com/exdb/mnist/下载数据集并用gzip解压
通过共享目录传递数据集到所有容器内。

进入spark-master
```
sudo docker exec -it spark-master /bin/bash
```
打开spark-shell

spark-shell位于/spark/bin目录下

使用```./spark-shell```命令进入spark-shell。

读取训练集

```
val train = spark.read.format("libsvm").load("/data/mnist_train.libsvm")
```

读取测试集
```
val test = spark.read.format("libsvm").load("/data/mnist_test.libsvm")
```
定义网络结构。如果计算机性能不好可以降低隐藏层的参数。
```
val layers = Array[Int](784, 784, 784, 10)
```
导入多层感知机与多分类评价器。
```
import org.apache.spark.ml.classification.MultilayerPerceptronClassifier
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
```
使用多层感知机初始化训练器。
```
val trainer = new MultilayerPerceptronClassifier().setLayers(layers).setBlockSize(128).setSeed(1234L).setMaxIter(100)
```
训练模型
```
var model = trainer.fit(train)
```
输入测试集进行识别
```
val result = model.transform(test)
```
获取测试结果中的预测结果与实际结果
```
val predictionAndLabels = result.select("prediction", "label")
```
初始化评价器
```
val evaluator = new MulticlassClassificationEvaluator().setMetricName("accuracy")
```
计算识别精度
```
println(s"Test set accuracy = ${evaluator.evaluate(predictionAndLabels)}")
```
在result上创建临时视图
```
result.toDF.createOrReplaceTempView("deep_learning")
```
使用Spark SQL的方式计算识别精度
```
spark.sql("select (select count(*) from deep_learning where label=prediction)/count(*) as accuracy from deep_learning").show()
```